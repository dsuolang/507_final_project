{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45793a28-b61a-49cb-8ded-12a4f066feeb",
   "metadata": {},
   "source": [
    "## SI507 Final Project : Data Checkpoint\n",
    "#### Author: Deji Suolang\n",
    "\n",
    "This python sciprt contains the code for data collection, census API and webscripping results from Zillow's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e186704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plot\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import regex as re\n",
    "import lxml\n",
    "import numbers\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce1c94",
   "metadata": {},
   "source": [
    "### Data Source 1: Census API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df20182-7911-432f-a2c3-6796a815925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching\n",
    "CACHE_FILENAME = 'cache.json'\n",
    "CACHE_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea2ffd28-b8b4-425c-a1b1-b94a884caa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_cache():\n",
    "    ''' opens the cache file if it exists and loads the JSON into\n",
    "    the FIB_CACHE dictionary.\n",
    "    \n",
    "    if the cache file doesn't exist, creates a new cache dictionary\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The opened cache: dict\n",
    "    '''\n",
    "    try:\n",
    "        cache_file = open(CACHE_FILENAME, 'r')\n",
    "        cache_contents = cache_file.read()\n",
    "        cache_dict = json.loads(cache_contents)\n",
    "        cache_file.close()\n",
    "    except:\n",
    "        cache_dict = {}\n",
    "    return cache_dict\n",
    "\n",
    "\n",
    "# converts the dictionary to JSON and saves it\n",
    "def save_cache(cache_dict):\n",
    "    ''' saves the current state of the cache to disk\n",
    "    Parameters\n",
    "    ----------\n",
    "    cache_dict: dict\n",
    "        The dictionary to save\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    dumped_json_cache = json.dumps(cache_dict)\n",
    "    fw = open(CACHE_FILENAME,\"w\")\n",
    "    fw.write(dumped_json_cache)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25838a94-294d-427e-9b15-958191e6cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_data(url):\n",
    "    '''this function will retrieve the median income data from Census API data\n",
    "    attainment data\n",
    "    '''\n",
    "    if os.path.isfile('cache.json') and os.access('cache.json', os.R_OK):\n",
    "        with open('cache.json', 'r', newline='') as cache_file:\n",
    "            cache = json.load(cache_file)\n",
    "            return cache\n",
    "\n",
    "    else:\n",
    "        cache = requests.get(url).text\n",
    "        census_data = json.loads(cache)\n",
    "        save_cache(census_data)\n",
    "        return census_data\n",
    "\n",
    "def clean_census_data(census_data):\n",
    "    '''cleans data and use county as the index\n",
    "    '''\n",
    "    county_dict = {}\n",
    "\n",
    "    for item in census_data:\n",
    "        county_dict[item[3].lower()] = item[1]\n",
    "        county_dict['county'] = 'median_income'\n",
    "        \n",
    "    return county_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "681ff19e-ff71-4005-8194-25ee1ec2a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Calling Census functions\n",
    "    census_data = get_census_data(\"https://api.census.gov/data/2019/acs/acs5?get=NAME,B19013_001E&for=tract:*&in=state:26&key=dfdb2a1eda26b816e1c7d71114a341b40b1b40b4\")\n",
    "    census_data = clean_census_data(census_data)\n",
    "    with open('census_data.csv', 'w') as f:\n",
    "        [f.write('{0},{1}\\n'.format(key, value)) for key, value in census_data.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9eb3b-3422-4ecc-8955-ce5bbff5456c",
   "metadata": {},
   "source": [
    "### Data Source 2: Zillow Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b5604dc-3cb6-4127-ba91-15205cf8a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'accept-encoding': 'gzip, deflate, br',\n",
    "    'accept-language': 'en-US,en;q=0.8',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "    }\n",
    "\n",
    "# We are intersted in the for sale home in the state of Michigan\n",
    "base_url = \"https://www.zillow.com/homes/for_sale/\"\n",
    "state = 'mi'\n",
    "\n",
    "def makesoup(data):\n",
    "    with requests.Session() as s:\n",
    "        r = s.get(data, headers=headers)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def get_zillow_results(data):\n",
    "    '''obtain useful variables from zillow scrapping results'\n",
    "    '''\n",
    "    address = data.find_all(class_= 'list-card-addr')\n",
    "    price = list(data.find_all(class_='list-card-price'))\n",
    "    bed_num = list(data.find_all(\"ul\", class_=\"list-card-details\"))\n",
    "     #create dataframe columns out of variables\n",
    "    df['prices'] = price\n",
    "    df['address'] = address\n",
    "    df['bed_num'] = bed_num\n",
    "    return df.copy()\n",
    "\n",
    "def get_url_list(base_url, state):\n",
    "    url_list = []\n",
    "    url_list.append(base_url +state+'/')\n",
    "    for i in range(2,26):\n",
    "        domain = base_url + state +'/'+str(i)+'_p/'\n",
    "        url_list.append(domain)\n",
    "    return url_list\n",
    "\n",
    "def create_soup_list(url_list):\n",
    "    soup_list = []\n",
    "    for url in url_list:\n",
    "        htmls = makesoup(url)\n",
    "        soup_list.append(htmls)\n",
    "    return soup_list\n",
    "\n",
    "def create_dataframe_list(soup_list):\n",
    "    df_list = []\n",
    "    for soup in soup_list:\n",
    "        new_df = get_zillow_results(soup)\n",
    "        df_list.append(new_df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "727ae0f0-8dbf-44e3-b139-da99939bbadb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_list = get_url_list(base_url, state)\n",
    "soup_list = create_soup_list(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4764fd36-c906-4922-ab2b-99f051502ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "zillow_df = pd.DataFrame()\n",
    "df_list = create_dataframe_list(soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8332b97-0593-4655-af0f-1b990b1b9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices</th>\n",
       "      <th>address</th>\n",
       "      <th>bed_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[$400,000]</td>\n",
       "      <td>[31008 Applewood Ln, Farmington, MI 48331]</td>\n",
       "      <td>[[4, [ ,  , bds]], [3, [ ,  , ba]], [2,944, [ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[$425,000]</td>\n",
       "      <td>[5372 Hauser Way, West Bloomfield, MI 48323]</td>\n",
       "      <td>[[4, [ ,  , bds]], [4, [ ,  , ba]], [3,213, [ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[$460,000]</td>\n",
       "      <td>[11526 Toledo Ave, Manitou Beach, MI 49253]</td>\n",
       "      <td>[[3, [ ,  , bds]], [2, [ ,  , ba]], [1,708, [ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[$579,900]</td>\n",
       "      <td>[6479 Island Lake Dr, East Lansing, MI 48823]</td>\n",
       "      <td>[[4, [ ,  , bds]], [4, [ ,  , ba]], [4,117, [ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[$75,000]</td>\n",
       "      <td>[26 Maple Ct, Muskegon, MI 49445]</td>\n",
       "      <td>[[3, [ ,  , bds]], [2, [ ,  , ba]], [1,512, [ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prices                                        address  \\\n",
       "0  [$400,000]     [31008 Applewood Ln, Farmington, MI 48331]   \n",
       "1  [$425,000]   [5372 Hauser Way, West Bloomfield, MI 48323]   \n",
       "2  [$460,000]    [11526 Toledo Ave, Manitou Beach, MI 49253]   \n",
       "3  [$579,900]  [6479 Island Lake Dr, East Lansing, MI 48823]   \n",
       "4   [$75,000]              [26 Maple Ct, Muskegon, MI 49445]   \n",
       "\n",
       "                                             bed_num  \n",
       "0  [[4, [ ,  , bds]], [3, [ ,  , ba]], [2,944, [ ...  \n",
       "1  [[4, [ ,  , bds]], [4, [ ,  , ba]], [3,213, [ ...  \n",
       "2  [[3, [ ,  , bds]], [2, [ ,  , ba]], [1,708, [ ...  \n",
       "3  [[4, [ ,  , bds]], [4, [ ,  , ba]], [4,117, [ ...  \n",
       "4  [[3, [ ,  , bds]], [2, [ ,  , ba]], [1,512, [ ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the list of datasets into our new dataframe\n",
    "zillow_df = pd.concat(df_list)\n",
    "zillow_df.reset_index(inplace=True)\n",
    "zillow_df = zillow_df.drop('index', axis=1)\n",
    "print(zillow_df.shape)\n",
    "zillow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bca4f045-670c-4482-9290-217a8a0ebe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_df = zillow_df.applymap(str)\n",
    "zillow_df = zillow_df.applymap(lambda x: re.sub('<[^<]+?>', '',x))\n",
    "zillow_df[['bed_num', 'home_type']] = zillow_df.bed_num.str.split('-',n=1, expand=True)\n",
    "zillow_df[['address', 'city','zip_code']] = zillow_df.address.str.split(\",\", expand=True)\n",
    "zillow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06856dc8-c976-43dd-8e4b-83bf855c199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate bed_num column into bed, bath, and sq_feet\n",
    "zillow_df[['bed_num', 'baths', 'sqft']] = zillow_df.bed_num.str.split(' ',n=2, expand=True)\n",
    "zillow_df['sqft'] = zillow_df.sqft.str.replace(\",\", \"\")\n",
    "# extract only the digits from the columns\n",
    "zillow_df['bed_num'] = zillow_df.bed_num.str.extract('(\\d+)')\n",
    "zillow_df['baths'] = zillow_df.baths.str.extract('(\\d+)')\n",
    "zillow_df['sqft'] = zillow_df.sqft.str.extract('(\\d+)')\n",
    "# convert columns to float\n",
    "zillow_df['bed_num'] = zillow_df['bed_num'].astype('float')\n",
    "zillow_df['baths'] = zillow_df['baths'].astype('float')\n",
    "zillow_df['sqft'] = zillow_df['sqft'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb9e2249-e07f-47a7-a500-6cf5d0fe318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_df[['state', 'zipcode']] = zillow_df.zip_code.str.split(expand=True)\n",
    "zillow_df['zipcode'] = zillow_df['zipcode'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5416995f-6a2b-431b-a07c-83fafd1ae834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add crosswalk between zipcode and county\n",
    "zip_county_crosswalk = pd.read_csv('zip_county_crosswalk.csv')\n",
    "# merge two dataset in order to add county infiormation\n",
    "zillow_df = zillow_df.merge(zip_county_crosswalk, how='inner', on='zipcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26e8cf57-009f-4bad-9988-02a588168594",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_df.to_csv('zillow_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
